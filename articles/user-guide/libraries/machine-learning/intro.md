---
title: Quantum Machine Learning Library
description: Quantum システムで machine learning を使用する方法について説明します
author: alexeib2
ms.author: alexeib
ms.date: 11/22/2019
ms.topic: conceptual
uid: microsoft.quantum.libraries.machine-learning.intro
no-loc:
- Q#
- $$v
ms.openlocfilehash: e2f4a4a63eef40474856426b3b29652b5d3053b2
ms.sourcegitcommit: 71605ea9cc630e84e7ef29027e1f0ea06299747e
ms.translationtype: MT
ms.contentlocale: ja-JP
ms.lasthandoff: 01/26/2021
ms.locfileid: "98854034"
---
# <a name="introduction-to-quantum-machine-learning"></a>クォンタム Machine Learning の概要

## <a name="framework-and-goals"></a>フレームワークと目標

クォンタムのエンコードと情報の処理は、従来の機械学習の量子分類子の強力な手段です。 特に、クォンタムレジスタのデータを特徴の数に対して簡潔にエンコードし、量子化を計算リソースとして使用し、クラスの推定のためにクォンタムの測定値を採用することができます。
サーキット中心のクォンタム分類器は、データのエンコードと高速な entangling/disentangling のクォンタム回線を結合した後、測定を使用してデータサンプルのクラスラベルを推定する、比較的単純なクォンタムソリューションです。
この目標は、非常に大規模な機能空間であっても、対象となる回線の特性とストレージを従来のように確保し、サーキットパラメーターのハイブリッド量子/古典トレーニングを行うことです。

## <a name="classifier-architecture"></a>分類子のアーキテクチャ

分類は、監視対象の機械学習タスクであり、 \{ 特定のデータサンプルのクラスラベル $ y_1、y_2、\ 点線、y_d $ を推論することを目標としてい \} ます。 "トレーニングデータセット" は、 \{ 既知の事前割り当て済みラベルを含むサンプル $ \mathcal{D} = (x, y)} $ のコレクションです。 ここで $x $ はデータ $y サンプルであり、$ は "トレーニングラベル" と呼ばれる既知のラベルです。
従来の方法とは少し似ていますが、クォンタム分類は次の3つの手順で構成されます。
- データのエンコード
- 分類子の状態の準備
- 測定値が確率論的になるため、この3つの手順を複数回繰り返す必要があります。 エンコーディングと分類子の状態の計算は、どちらも *クォンタム回線* を介して行われます。 エンコーディング回線は通常、データドリブンで、パラメーター化されていませんが、分類器回線には、learnable パラメーターの十分なセットが含まれています。 

提案されたソリューションでは、分類器回線は、単一の qubit 回転と2つのビット制御の回転で構成されます。 Learnable パラメーターは、回転角度です。 回転および制御された回転ゲートは、クォンタムの計算では *ユニバーサル* であることがわかっています。つまり、すべてのユニタリウェイトの行列は、このようなゲートで構成される十分な長さの回線に分解できます。

提案されたバージョンでは、1つの回線の後に1つの頻度の推定が続きます。
そのため、このソリューションは、低レベルの多項式カーネルを使用したサポートベクターマシンの量子アナログです。

![多層パーセプトロンとサーキット中心の分類器](~/media/DLvsQCC.png)

単純なクォンタム分類器の設計は、従来のサポートベクターマシン (SVM) ソリューションと比較できます。 SVM の場合 $x $ \ sum \ alpha_j k (x_j, x) $ というデータサンプルの推定値が使用されます。ここで $k $ は特定のカーネル関数です。

これに対して、クォンタム分類子は、予測 $p (y │ x, U (-シータ)) = 〈 U (-シータ) x | M | U (-シータ) x 〉 $ を使用します。これは、スピリットに似ていますが、技術的には大きく異なります。 したがって、単純な振幅エンコードが使用されている場合、$p (y │ x, U (-シータ)) $ は $x $ の振幅の2次形式ですが、この形式の係数は独立して学習されなくなりました。代わりに、サーキット $U (\ シータ) $ のマトリックス要素から集計されます。この場合、通常、ベクトル $x $ の次元よりも learnable パラメーター $/シータ $ が大幅に減少します。 元の特徴の $p (y │ x, U (-シータ)) $ の多項式次数は、$x $ の $l $ コピーでクォンタム製品エンコードを使用して、$ 2 ^ l $ に増やすことができます。

このアーキテクチャでは比較的浅い回線が検討されています。そのため、すべての範囲のデータ機能間のすべての相関関係をキャプチャするために、 *迅速に entangling* する必要があります。 次の図に、最も役に立つ entangling サーキットコンポーネントの例を示します。 このジオメトリを持つ回線は、$3 n + 1 $ ゲートのみで構成されていますが、計算されるユニタリ weight 行列によって、$ 2 ^ n $ の特徴間で重要な相互通信が行われます。

![(2 つの循環レイヤーがある) 5 つの qubits 上で、entangling のクォンタム回線を高速にします。](~/media/5-qubit-qccc.png)

上の例のサーキットは6つのシングル qubit ゲート $ (G_1、\ lドット、G_5 で構成されています。G_ {16} ) $ および 10 2-qubits ゲート $ (G_6、\ lドット、G_ {15} ) $。 各ゲートが1つの learnable パラメーターを使用して定義されていると仮定すると、16 learnable パラメーターがありますが、5 qubit ヒルベルト space の次元は32です。 このようなサーキットジオメトリは任意の $n $-qubit レジスタに簡単に一般化できます。 $n $ が奇数の場合、$ 2 ^ n $ 次元の特徴空間の $3 n + 1 $ パラメーターを使用して回線を生成します。

## <a name="classifier-training-as-a-supervised-learning-task"></a>監視学習タスクとしての分類器トレーニング

分類器モデルのトレーニングでは、その操作パラメーターの最適な値が検索されます。これにより、トレーニングサンプル全体で正しいトレーニングラベルが推定される確率が最大になります。
ここでは、2つのレベルの分類のみを考慮しています。つまり、$d = $2 の場合は、ラベルが _1 $y _1、y_2 $ の2つのクラスのみです。

> [!NOTE]
> 任意の数のクラスに対してメソッドを一般化する約束の方法として、qubits を qudits に置き換えます。つまり、$d $ basis 状態のクォンタム単位と、$d $ ウェイの測定値を持つ双方向の測定値を置き換えます。

### <a name="likelihood-as-the-training-goal"></a>トレーニング目標としての確率

Learnable クォンタム回線 $U (\ シータ) $ と指定した場合、$/シータ $ はパラメーターのベクトルで、$M $ によって最終的な測定値を示します。正しいラベル推定の平均確率は $ $ \begin{align} \mathcal{L} (\ シータ) = {1} (\ sum_ {(x, y_1) \In\mathcal{D}} P (M = y_1 | です。U (\ シータ) x) + \ sum_ {(x, y_2) \in\mathcal{D}} P (M = y_2 |U (& シータ) x) \ right) \end{align} $ $ where $P (M = y | z) $ は、クォンタム状態 $z $ の $y $ を測定する確率です。
ここでは、尤度関数 $ \mathcal{L} (\ シータ) $ が $/シータ $ に smooth、$ \ theta_j $ の派生物が、実質的に尤度関数自体を計算するために使用するのと同じクォンタムプロトコルによって計算されることを理解しておく必要があります。 これにより、グラデーション降下による $ \mathcal{L} (\ シータ) $ の最適化が可能になります。

### <a name="classifier-bias-and-training-score"></a>分類器バイアスとトレーニングスコア

$-シータ $ 内のパラメーターの中間 (または最終) 値を指定する場合は、推定を行うために、$ $b を *分類子バイアス* として1つの実数値として指定する必要があります。 ラベルの推定規則は、次のように動作します。 
- サンプル $x $ には、$P の場合にのみ、ラベル $y _2 $ が割り当てられます (M = y_2 |U (\ シータ) x) + b > $0.5 (RULE1) (それ以外の場合は、ラベル $y _1 $) が割り当てられます。

明確に $b $ は、意味のある $ (-0.5, + 0.5) $ の範囲内である必要があります。

\Mathcal{D} $ のトレーニングケース $ (x, y) \ は、RULE1 による $ として $x 推論されるラベルが、実際には $y $ とは異なる場合に $b $ で *間違った分類* と見なされます。 誤分類の全体的な数は、分類器の *トレーニングスコア* であり、バイアス $b $ になります。 *最適* な分類子バイアス $b $ は、トレーニングスコアを最小化します。 事前計算済み確率推定値 $ \{ P (M = y_2 | を指定すると、これを簡単に確認できます。U (\ シータ) x) |(x, *) \in\mathcal{D} \} $,、最大 $ \ log_2 (| \mathcal{D} |) を作成することによって、間隔 $ (-0.5, + 0.5) $ のバイナリ検索で最適な分類子バイアスを見つけることができます。$ steps。

### <a name="reference"></a>リファレンス

この情報は、コードの再生を開始するのに十分なものである必要があります。 ただし、このモデルの詳細については、 [ *「回線中心のクォンタム分類子」、「Alex Bocharov、Krysta svore、および Nathan Wiebe」* の提案をお読みください。](https://arxiv.org/abs/1804.00633)

次の手順で示すコードサンプルに加えて、[このチュートリアル](https://github.com/microsoft/QuantumKatas/tree/main/tutorials/QuantumClassification)の「クォンタム分類」も参照してください。 
